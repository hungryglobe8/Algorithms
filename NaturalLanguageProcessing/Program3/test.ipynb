{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c4ca25f5a61e7748aa2257e1b5b815b7df522a7e2e437a65b6adcaa1b7b5987"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"<occurrence>list\"\n",
    "word = word.lower()\n",
    "pattern = r\"[a-z]\"\n",
    "stopwords = [\"you'd, would\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word not in stopwords and re.search(pattern, word) and not word.startswith(\"<occurrence>\"):\n",
    "    print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vec = [3, 4, 0, 1, 5]\n",
    "y_vec = [2, 1, 1, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "distsim.Signature_Vector.cosine_sim(x_vec, y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-6f18eb4339a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"test.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstopwords_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"stopwords.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistsim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistsim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGoldSentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtest_sentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistsim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistsim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistsim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Casey\\source\\repos\\ClassProjects\\NaturalLanguageProcessing\\Program3\\distsim.py\u001b[0m in \u001b[0;36mread_from_file\u001b[1;34m(file_name, class_name)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                     \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                     \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Casey\\source\\repos\\ClassProjects\\NaturalLanguageProcessing\\Program3\\distsim.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mlead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"GOLDSENSE:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mSentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_folder = \"./data/\"\n",
    "train_file = \"./apostrophes.txt\"\n",
    "test_file = test_folder + \"test.txt\"\n",
    "stopwords_file = test_folder + \"stopwords.txt\"\n",
    "sentences = distsim.read_from_file(train_file, distsim.GoldSentence)\n",
    "test_sentences = distsim.read_from_file(test_file, distsim.Sentence)\n",
    "stopwords = distsim.read_from_file(stopwords_file)\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = distsim.get_context_window(sentences, k, stopwords)\n",
    "senses = distsim.get_unique_senses(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2647"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['suddenly',\n",
       " 'suggested',\n",
       " 'suit',\n",
       " 'suits',\n",
       " 'summer',\n",
       " 'sun',\n",
       " 'super',\n",
       " 'supercomputer',\n",
       " 'supermarket',\n",
       " 'supermarkets',\n",
       " 'supplement',\n",
       " 'supplier',\n",
       " 'suppliers',\n",
       " 'supplies',\n",
       " 'support',\n",
       " 'supported',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'surface',\n",
       " 'surgical',\n",
       " 'survive',\n",
       " 'swift',\n",
       " 'swinging',\n",
       " 'switch',\n",
       " 'switched',\n",
       " 'switches',\n",
       " 'switching',\n",
       " 'system',\n",
       " 'system/2',\n",
       " 'systems',\n",
       " 'table',\n",
       " 'tactic',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'takeover',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'tandy',\n",
       " 'tank',\n",
       " 'taurus',\n",
       " 'taut',\n",
       " 'tax',\n",
       " 'taxes',\n",
       " 'taylor',\n",
       " 'tea',\n",
       " 'teacher',\n",
       " 'team',\n",
       " 'tech',\n",
       " 'technical',\n",
       " 'technology',\n",
       " 'teddy',\n",
       " 'teen',\n",
       " 'telecommunications',\n",
       " 'telephone',\n",
       " 'telesis',\n",
       " 'television',\n",
       " 'tell',\n",
       " 'teller',\n",
       " 'tennis',\n",
       " 'terminals',\n",
       " 'territory',\n",
       " 'terrorists',\n",
       " 'test',\n",
       " 'tested',\n",
       " 'testing',\n",
       " 'tests',\n",
       " 'texas',\n",
       " 'textiles',\n",
       " 'theme',\n",
       " 'theory',\n",
       " 'thin',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinks',\n",
       " 'third',\n",
       " 'thomson',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'thousand',\n",
       " 'threatened',\n",
       " 'three',\n",
       " 'threw',\n",
       " 'throw',\n",
       " 'throwaway',\n",
       " 'throwing',\n",
       " 'thursday',\n",
       " 'thus',\n",
       " 'ticket',\n",
       " 'tied',\n",
       " 'tight',\n",
       " 'tighten',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tiny',\n",
       " 'tip',\n",
       " 'tips',\n",
       " 'tire',\n",
       " 'tired',\n",
       " 'tires',\n",
       " 'tobacco',\n",
       " 'today',\n",
       " 'together',\n",
       " 'toiletries',\n",
       " 'tokyo',\n",
       " 'told',\n",
       " 'toll',\n",
       " 'tom',\n",
       " 'tomato',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'toothpaste',\n",
       " 'top',\n",
       " 'tossed',\n",
       " 'tossing',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'touches',\n",
       " 'tough',\n",
       " 'tow',\n",
       " 'toward',\n",
       " 'tower',\n",
       " 'town',\n",
       " 'toy',\n",
       " 'toyota',\n",
       " 'toys',\n",
       " 'tractor',\n",
       " 'trade',\n",
       " 'trademark',\n",
       " 'traders',\n",
       " 'trading',\n",
       " 'traditional',\n",
       " 'traffic',\n",
       " 'trailing',\n",
       " 'transaction',\n",
       " 'transactions',\n",
       " 'transformers',\n",
       " 'transmission',\n",
       " 'transmit',\n",
       " 'transmitted',\n",
       " 'transportable',\n",
       " 'travel',\n",
       " 'travelers',\n",
       " 'tread',\n",
       " 'treading',\n",
       " 'treatment',\n",
       " 'tree',\n",
       " 'trial',\n",
       " 'tried',\n",
       " 'trim',\n",
       " 'tropicana',\n",
       " 'trouble',\n",
       " 'troubling',\n",
       " 'truck',\n",
       " 'trucks',\n",
       " 'trust',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'tube',\n",
       " 'tuesday',\n",
       " 'tug',\n",
       " 'tuna',\n",
       " 'turn',\n",
       " 'turned',\n",
       " 'turns',\n",
       " 'tv',\n",
       " 'tvs',\n",
       " 'twine',\n",
       " 'twisted',\n",
       " 'twisting',\n",
       " 'two',\n",
       " 'tyco',\n",
       " 'type',\n",
       " 'types',\n",
       " 'typewriters',\n",
       " 'typical',\n",
       " 'typically',\n",
       " 'u.s.',\n",
       " 'ugly',\n",
       " 'unbroken',\n",
       " 'underground',\n",
       " 'understand',\n",
       " 'unilever',\n",
       " 'union',\n",
       " 'uniroyal',\n",
       " 'unisys',\n",
       " 'unit',\n",
       " 'united',\n",
       " 'units',\n",
       " 'universe',\n",
       " 'unix',\n",
       " 'unless',\n",
       " 'unprofitable',\n",
       " 'untied',\n",
       " 'unveil',\n",
       " 'unveiled',\n",
       " 'unveiling',\n",
       " 'upgrade',\n",
       " 'upgraded',\n",
       " 'upon',\n",
       " 'upscale',\n",
       " 'urging',\n",
       " 'us',\n",
       " 'usage',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'users',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usual',\n",
       " 'usually',\n",
       " 'utility',\n",
       " 'utters',\n",
       " 'vacuum',\n",
       " 'valuable',\n",
       " 'value',\n",
       " 'vanished',\n",
       " 'variety',\n",
       " 'various',\n",
       " 'vax',\n",
       " 'vectra',\n",
       " 'vegetables',\n",
       " 'vehicles',\n",
       " 'venture',\n",
       " 'verse',\n",
       " 'version',\n",
       " 'versions',\n",
       " 'vice',\n",
       " 'victims',\n",
       " 'video',\n",
       " 'view',\n",
       " 'vinegars',\n",
       " 'vineyards',\n",
       " 'vintage',\n",
       " 'virtually',\n",
       " 'virus',\n",
       " 'visible',\n",
       " 'voice',\n",
       " 'voices',\n",
       " 'volume',\n",
       " 'von',\n",
       " 'vote',\n",
       " 'voters',\n",
       " 'wagon',\n",
       " 'wait',\n",
       " 'waited',\n",
       " 'waiting',\n",
       " 'waits',\n",
       " 'walk',\n",
       " 'walking',\n",
       " 'walks',\n",
       " 'wall',\n",
       " 'wang',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wanting',\n",
       " 'wants',\n",
       " 'war',\n",
       " 'warned',\n",
       " 'warrant',\n",
       " 'wash',\n",
       " 'washington',\n",
       " 'waste',\n",
       " 'water',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'weak',\n",
       " 'weapons',\n",
       " 'wear',\n",
       " 'weather',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weighted',\n",
       " 'welfare',\n",
       " 'well',\n",
       " 'wellcraft',\n",
       " 'went',\n",
       " 'wesson',\n",
       " 'west',\n",
       " 'western',\n",
       " 'whale',\n",
       " 'wheel',\n",
       " 'wheels',\n",
       " 'wheelwriter',\n",
       " 'whenever',\n",
       " 'whether',\n",
       " 'whirlpool',\n",
       " 'white',\n",
       " 'whole',\n",
       " 'wholesale',\n",
       " 'whose',\n",
       " 'wide',\n",
       " 'widen',\n",
       " 'widespread',\n",
       " 'wife',\n",
       " 'wild',\n",
       " 'williams',\n",
       " 'willing',\n",
       " 'wilson',\n",
       " 'wind',\n",
       " 'wines',\n",
       " 'winning',\n",
       " 'wire',\n",
       " 'wis.',\n",
       " 'wisconsin',\n",
       " 'withdraw',\n",
       " 'withdrew',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wo',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'wooden',\n",
       " 'word',\n",
       " 'words',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'workers',\n",
       " 'working',\n",
       " 'workings',\n",
       " 'workstation',\n",
       " 'workstations',\n",
       " 'world',\n",
       " 'worrying',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'wrapped',\n",
       " 'wrist',\n",
       " 'write',\n",
       " 'written',\n",
       " 'wrote',\n",
       " 'x',\n",
       " 'xerox',\n",
       " 'yards',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'york',\n",
       " 'young',\n",
       " 'youth']"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "vocab[2300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_signature_vectors = distsim.make_sig_vectors(senses, sentences, vocab, k)\n",
    "test_signature_vectors = distsim.make_norm_sig_vectors(senses, test_sentences, vocab, k)\n",
    "\n",
    "test_scores = list()\n",
    "for vec in test_signature_vectors.values():\n",
    "    sentence_scores = list()\n",
    "    for other_vec in train_signature_vectors.values():\n",
    "        sentence_scores.append(vec.cosine_sim(other_vec, other_vec.sense))\n",
    "    test_scores.append(sentence_scores)\n",
    "\n",
    "res = distsim.sorted_scores(test_scores)\n",
    "print(res)"
   ]
  }
 ]
}